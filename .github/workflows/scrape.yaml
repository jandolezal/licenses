
# https://simonwillison.net/2020/Oct/9/git-scraping/

name: Scrape data every Friday

on:
  workflow_dispatch:
  schedule:
    - cron: "00 19 * * 5"

jobs:
  build:
    runs-on: ubuntu-latest

    steps:
    - name: Checkout this repo
      uses: actions/checkout@v2
    - name: Set up Python
      uses: actions/setup-python@v2
      with:
        python-version: 3.9

    - name: Install dependencies
      run: |-
        python3 -m pip install --upgrade pip
        python3 -m pip install -r requirements.txt
        heroku plugins:install heroku-builds

    - name: Scrape data from Energy Regulatory Office
      run: |-
        scrapy crawl holder -O data/holder.csv
        scrapy crawl heatgen
        scrapy crawl electricitygen
        csvs-to-sqlite data/druh.csv licenses.db

    - name: Push database to Heroku
      run: |-
        datasette publish heroku licenses.db -n licenses-ero
      env:
        HEROKU_API_KEY: ${{ secrets.HEROKU_API_KEY }}


    - name: Commit and push if it changed
      run: |-
        git config user.name "Automated"
        git config user.email "actions@users.noreply.github.com"
        git add -A
        timestamp=$(date -u)
        git commit -m "Latest actual data: ${timestamp}" || exit 0
        git push
